# КЛАССИФИКАЦИЯ ТЕКСТОВ НА МАЛЕНЬКИХ ДАТАСЕТАХ C ПОМОЩЬЮ ML 

Задачи классификации текстов имеют широкие перспективы в связи с тем, что огромное количество текстового контента, такого как новостные статьи, обзоры продуктов, и публикации в социальных сетях, публикуются каждый день благодаря простоте создания и обмена информацией в Интернете.

Пользователи вынуждены тратить все больше времени на прочтение и отсеивание ненужной информации. Современные подходы традиционной классификации текстов плохо работают с короткими текстами, если их применять напрямую.

Многообразие имеющихся алгоритмов и отсутствие универсального решения определяет необходимость постоянно улучшать и оптимизировать текущие алгоритмы классификации.

Автоматическое извлечение информации из текстов представляет интерес и как научная проблема, и как эффективный аналитический инструмент.

В работе на примере маленьких датасетов русскоязычного корпуса новостных данных: 

исследуется ряд подходов к обработке и классификации неструктурированной текстовой информации, 

рассматриваются задачи выделения группы наиболее подходящих алгоритмов машинного обучения и поиска их оптимальных параметров для выполнения классификации текстовой информации. 

производится сравнительный анализ выбранных алгоритмов. 

Иными словами, алгоритмы были протестированы на реальных данных, имеющих свою специфику и особенности.

Для обучения устойчивой модели машинного обучения требуется большое количество размеченных данных. Предметная область (корпус новостных данных на русском языке) зачастую не обладает большим количеством размеченных целевых сущностей и предметных отношений. Поэтому для решения задачи был применен метод с частичным обучением (semi-supervised learning, SSL), который в процессе обучения использует не только размеченные, но и неразмеченные данные, что позволяет алгоритму извлекать больше информации и меньше реагировать на “выбросы” в исходных данных. 

Были получены следующие результаты:

разработана и обучена модель классификации текстов с помощью SSL и подтверждена успешная применимость данного подхода; 

при обучении использовались алгоритмы: наивный байесовский метод, метод опорных векторов, случайный лес, логистическая регрессия, метод k-ближайших соседей. Были также использованы: выделение n-грамм и наиболее часто встречающихся слов, тематическое моделирование BIGARTM для группировки новостей по категориям, FastText для валидации неразмеченных данных, многослойный перцептрон, RNN (LTSM), BERT с эмбеддингами из библиотеки DeepPavlov. Была проведена кластеризация. Но кластеры не совпали даже близко с проставленными метками. Этот способ для дальнейшего использования был отвергнут.

проведена количественная оценка результатов применения алгоритмов. 

Качество модели SSL довольно высокое даже при наличии небольшого количества размеченных примеров (2069).

Алгоритм FastText был выбран как валидационный. 

Применённые алгоритмы показали хорошие результаты, на основании которых можно сделать вывод о возможности их успешного применения для классификации текстов на маленьких датасетах с помощью машинного обучения по схеме частичного обучения. 

Работа показывает, что предложенный подход является достаточно эффективным. Неразмеченные данные, при использовании в сочетании с небольшим количеством размеченных данных, могут значительно улучшить точность обучения.

Следует отметить существующие сложности: 

присутствует субъективность разметки и восприятия новости человеком: то есть новость может быть воспринята каждым человеком по-своему. Для одного нейтральная, для другого положительная, для третьего – негативная;

при работе с языковыми конструкциями, написанными на естественном языке, возникает множество сложностей, связанных с уникальностью русского языка, а также с пониманием программы контекста.

В качестве дальнейшего направления развития темы классификации текстов можно выделить разработку критериев подбора фрагментов для обучающего набора данных, так как алгоритм подбора данных играет ключевую роль в качестве обучения модели.
